# El arcano arte de entrenar redes neuronales
Material extendido.
    
### Recursos mencionados durante la charla
* [PaperWithCode](https://paperswithcode.com/sota): Una página web en la cual se
  puede explorar rápidamente el estado del arte en una gran variedad de tareas y
  modalidades.
* [NLP-progress](http://nlpprogress.com/): Similar a PaperWithCode, pero
  enfocado en NLP.
* [Computer Vision recipes](https://github.com/microsoft/computervision-recipes)
  Una recopilación de buenas prácticas, ejemplos y documentación para construir
  modelos de vision.
* [NLP recipes](https://github.com/microsoft/nlp-recipes)
  Una recopilación de buenas prácticas, ejemplos y documentación para construir
  modelos de NLP.
* [Bag of Tricks for Image Classification with Convolutional Neural Networks (He
  at al, 2018)](https://arxiv.org/pdf/1812.01187.pdf) Un artículo de AWS en el
  cual presentan un par de trucos para boostear el performance en clasificación
  de imagen

### Herramientas mencionadas durante la charla
* [platform.ai](https://platform.ai/) La herramienta de etiquetado de Jeremy
  Howard, en [esta charla](https://youtu.be/t4kyRyKyOpo?t=782) explica bastante
  mejor su potencial
* [Hypothesis](https://github.com/HypothesisWorks/hypothesis) Librería de python
  que nos permite crear test unitarios basados en propiedades en lugar de
  ejemplos, en [esta charla](https://youtu.be/0ysyWk-ox-8) de PyCon2019 explican
  bastante bien cómo utilizarla adecuadamente en la vida de un data scientist
* [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) Es
  una librería de Pytorch que busca hacer más fácil la vida de los investigadores
  de Deep learning.
* [Optuna](https://optuna.org/) Una librería para realizar hyperparameter tuning
  usando bayesian optimization y otros métodos fancies
* [Weights & Biases](https://www.wandb.com/) Trackeo de experimento llevado a
  otro nivel, definitivamente es un must cuando se está trabajando en equipo
### Recursos en los cuales me inspiré para crear la charla
* [Writing code for NLP Research](https://github.com/allenai/writing-code-for-nlp-research-emnlp2018/blob/master/writing_code_for_nlp_research.pdf) 
  Un tutorial realizado en EMNLP 2018 por Allen Institute for AI, en el cual
  presentan varias buenas prácticas para realizar mejor código.
* [Nuts and Bolts of Applying Deep
  Learning](https://www.youtube.com/watch?v=F1ka6a13S9I) Una tutorial realizado
  por Andrew Ng en NeurIPS2016, en el cual presenta varias buenas prácticas para
  tener mejores modelos de DL tanto en la industria como en la academia.
* [Machine Learning
  Yearning](https://www.deeplearning.ai/machine-learning-yearning/) El libro de
  Andrew Ng en el cual habla sobre como crear un proyecto de machine learning
  exitoso.
* [Deep learning book (Capitulo
  11)](http://www.deeplearningbook.org/contents/guidelines.html) En este
  capítulo se presentan tips prácticos para entrenar modelo de deep learning.
* [Practical Advice for Building Deep Neural
  Networks](https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/)
  Un blog post bastante completo en el cual se ilustran tips para entrenar redes
  neuronales
* [A Recipe for Training Neural
  Networks](http://karpathy.github.io/2019/04/25/recipe/) Un blog post con un
  espíritu muy similar al anterior, pero con un enfoque bastante más
  metodologico.
### Otros recursos
* [Nuts and Bolts of Deep RL
  Experimentation](https://www.youtube.com/watch?v=8EcdaCk9KaQ) Una charla por
  John Schulman en la cual presenta varias buenas prácticas para tener mejores
  modelos de Deep RL.
